    Esta clase va a ser
        grabad
          a
              Clase 14. DATA SCIENCE 
         Modelos Anal√≠ticos 
              para DS II
      Temario
                       13                      14                      15
                    Modelos                 Modelos                Modelos 
                anal√≠ticos para         anal√≠ticos para         anal√≠ticos para 
                      DS I                    DS II                  DS III
                ‚úì Modelo anal√≠tico        ‚úì Recapitulaci√≥n
                                                                  ‚úì Modelo anal√≠tico 
                ‚úì Machine                 ‚úì Aprendizaje 
                   Learning                  supervisado          ‚úì Reglas de 
                                          ‚úì Clasificaci√≥n            asociaci√≥n
                ‚úì Ciencia de                                      ‚úì
                   datos: etapas          ‚úì KNN                      Reducci√≥n de 
                                                                     dimensionalidad
                ‚úì Conceptos               ‚úì Regresi√≥n
                   complementario
                   s
    Objetivos de la clase
                 Profundizar en el tipo de Aprendizaje 
                 Supervisado.
                 Identificar algoritmos principales de 
                 Clasificaci√≥n y Regresi√≥n.
              MAPA DE CONCEPTOS
                                                                                                     √Årbol de 
                                                                        Clasificaci√≥n                decisi√≥n
                                                                                                     K-Nearest-
                                                                                                     Neighbor
             Modelos                                                                                 Regresi√≥n 
             Anal√≠ticos para                                                                         log√≠stica
                                          Aprendizaje 
             Ciencia de Datos             Supervisado
             II
                                                                        Regresi√≥n
  Momento de repaso
    Recapitulaci√≥n de 
     la clase anterior
       Para pensar
   ¬øQu√© es Machine Learning?
   ¬øQu√© es un Modelo Anal√≠tico? 
   Contesta mediante el chat de Zoom 
       Repaso‚Ä¶
       En la clase de Modelos Anal√≠ticos para      Entonces son diferentes algoritmos que 
       DS I, comentamos que Machine Learning,      nosotros podemos desarrollar, en funci√≥n 
       es un m√©todo de an√°lisis de datos que       de la problem√°tica del negocio como as√≠ 
       automatiza la construcci√≥n de ‚ÄúModelos      tambi√©n, del tipo de aprendizaje que 
       Anal√≠ticos‚Äù.                                queramos aplicar.
       ¬øY ahora?
       En esta sesi√≥n, vamos a profundizar en el      As√≠ que primero, recordemos:
       Tipo de Aprendizaje Supervisado, sus            Ì¥îÌ†æ ¬øCu√°l es el objetivo principal del 
       caracter√≠sticas, particulares y los            Aprendizaje Supervisado? 
       principales algoritmos que podemos 
       encontrar.                                     Predecir las respuestas que habr√° en 
                                                      el futuro, gracias al entrenamiento 
                                                      del algoritmo con datos conocidos 
                                                      del pasado (datos hist√≥ricos).
      Aprendizaje
      supervisado
      Aprendizaje 
      supervisado
       ‚úî Es  una  subcategor√≠a   del  aprendizaje 
          autom√°tico y la IA. 
       ‚úî Se define por el uso de conjuntos de datos 
          etiquetados  para  entrenar  algoritmos  que 
          clasifiquen  datos  o  predigan  resultados  con 
          precisi√≥n. 
       ‚úî El  aprendizaje  supervisado  ayuda  a  las 
          organizaciones a resolver una variedad de 
          problemas del mundo real a gran escala, 
          por ejemplo clasificar el correo no deseado o 
          detectar fraude.
       Recapitulaci√≥n: Tipos 
       problemas aprendizaje 
       supervisado 
       En la clase 12 vimos que exist√≠an dos           A la hora de decidir cu√°l tipo de algoritmo 
       tipos de problemas comunes en el                a usar debemos tener claro lo siguiente‚Ä¶
       Aprendizaje Supervisado.
       Recapitulaci√≥n: Tipos 
       problemas aprendizaje 
       supervisado 
                      Regresi√≥n                                  Clasificaci√≥n
        ‚úî Requiere la predicci√≥n de una              ‚úî Requiere variable objetivo con dos o 
            variable continua.                           m√°s clases.
        ‚úî Puede tener como entrada valores           ‚úî Puede tener variables de entrada 
            continuos o discretos.                       discretas o continuas.
        ‚úî Un problema con m√∫ltiples variables        ‚úî Un problema con dos clases se 
            de entrada a menudo se denomina              denomina problema de clasificaci√≥n 
            problema de regresi√≥n multivariante.         binaria y con m√°s de dos 
                                                         clasificaci√≥n multiclase.
      Clasificaci√≥n
       Problemas de 
       clasificaci√≥n
       Reconocen entidades espec√≠ficas dentro del                           REEPLAZAR 
       conjunto de datos e intenta obtener conclusiones                     POR IMAGEN
       sobre c√≥mo esas entidades deben etiquetarse o 
       definirse. 
       Los algoritmos de clasificaci√≥n comunes son 
       clasificadores lineales, m√°quinas de vectores de 
       soporte (SVM), √°rboles de decisi√≥n, k-nearest 
       Neighbor y Random Forest
       Tipos de 
       Problemas en 
       clasificaci√≥n                                                               REEMPLAZAR 
                                                                                    POR IMAGEN
       Tenemos dos grandes tipos: problemas de 
       clasificaci√≥n binaria y multiclase
         ‚úî Clasificaci√≥n binaria: Clasifica los datos en dos 
             clases, como Si/No, bueno/malo, alto/bajo, 
             padece una enfermedad en particular o no, 
             etc.
         ‚úî Clasificaci√≥n multiclase: Clasifica datos en tres 
             o m√°s clases; por ej. clasificaci√≥n de 
             documentos, categorizaci√≥n de productos, 
             clasificaci√≥n de malware
       Nota: No es conveniente tener muchas categor√≠as en los problemas de clasificaci√≥n
    Ejemplos 
    Problemas de 
    clasificaci√≥n
     ‚úî Predicci√≥n comportamiento de clientes
     ‚úî Clasificaci√≥n de documentos
     ‚úî Clasificaci√≥n de im√°genes
     ‚úî Clasificaci√≥n de texto web
     ‚úî Predicci√≥n de la tasa de clics de los anuncios
     ‚úî Categorizaci√≥n de productos
     ‚úî Clasificaci√≥n de Malware
     ‚úî Detecci√≥n de fraude
     ‚úî An√°lisis de sentimientos de im√°genes
    Otros 
    ejemplos‚Ä¶
     ‚úî Evaluaci√≥n para ofertas promocionales
     ‚úî Problemas de detecci√≥n de anomal√≠as
     ‚úî Fraude en tarjetas de cr√©dito
     ‚úî Validaci√≥n de deducciones
     ‚úî Evaluaci√≥n de solvencia crediticia
     ‚úî Recomendaciones para liberaci√≥n de √≥rdenes
     ‚úî An√°lisis de sentimiento
     ‚úî Predicci√≥n de abandono de clientes
    Tipos de algoritmos 
     de clasificaci√≥n
                         Algoritmos          Abreviaci√≥n    Muestras 
                                                           ponderadas?
                      AdaBoostClassifier         ABC            Si
                     Gaussian Naive Bayes       GNB             Si
                          Classifier
                          LightGBM               LGB            Si
                  Gradient Boosting Classifier   GBC            Si
                     K-nearest Neighbours        KNN            No
                          Classifier
                  Linear Discriminant Analysis   LDA            No
                        Decision Trees           DT             No
      Fuente: Adaptado de Stenhouse K et al. (2021).
      En Morado algoritmos m√°s populares 
                               Algoritmos                Abreviaci√≥         Muestras 
                                                               n          ponderadas?
                       Logistic Regression Classifier         LRC               Si
                     Multi-layer Perceptron Classifier       MLPC               No
                        Nearest Centroid Classifier          NCC                No
                       Nu-Support Vector Classifier         nuSVC               Si
                     Quadratic Discriminant Analysis         QDA                No
                         Random forest Classifier             RFC               Si
                                 XGBOOST                     XGB                Si
       Fuente: Adaptado de Stenhouse K et al. (2021).
       En Morado algoritmos m√°s populares 
       Aprendizaje Supervisado | 
       Clasificaci√≥n
       Como vimos anteriormente existen 
       m√∫ltiples algoritmos de clasificaci√≥n, a 
       continuaci√≥n compartiremos aquellos m√°s 
       populares. 
              √Årbol de decisi√≥n             K-Nearest-Neighbor             Regresi√≥n log√≠stica
    √Årboles de decisi√≥n
       Definici√≥n
         ‚úî Son estructuras matem√°ticas (diagramas de 
            flujo) que utilizan criterios de teor√≠a de la 
            informaci√≥n como la impureza (Gini, entrop√≠a)                    REEMPLAZAR 
            para hacer segmentaciones                                        POR IMAGEN
         ‚úî El aprendizaje basado en √°rboles de decisi√≥n 
            est√° ampliamente extendido en la actualidad, 
            y m√∫ltiples modelos hacen diferentes 
            implementaciones de los mismos. 
         ‚úî Las primeras versiones de estos modelos 
            fueron implementados por Leo Breiman. 
         ‚úî Se utilizan para problemas de Clasificaci√≥n y 
            Regresi√≥n.
                       Definici√≥n
                       ‚úî Aprenden de los datos generando reglas de tipo if-
                         else. 
                       ‚úî Separan los datos en grupos cada vez m√°s 
                         peque√±os de subsets de un dataset original. 
                       ‚úî A cada divisi√≥n se la conoce con el nombre de 
                         nodo. Cuando un nodo no conduce a nuevas 
                         divisiones se le denomina hoja, para luego ser 
                         considerada como ramas del √°rbol. 
 √Årboles de Decisi√≥n
                        REEMPLAZAR 
                        POR IMAGEN
    Partes de los √°rboles 
       de decisi√≥n
                       Partes de los 
                       √Årboles de 
                       Decisi√≥n
                       ‚úî Nodo ra√≠z: Representa a toda la poblaci√≥n o 
                         muestra y esto se divide en dos o m√°s conjuntos 
                         homog√©neos.
                       ‚úî Divisi√≥n: Es un proceso de divisi√≥n de un nodo en 
                         dos o m√°s subnodos. 
                       ‚úî Nodo de decisi√≥n: Cuando un subnodo se divide 
                         en subnodos adicionales, se llama nodo de 
                         decisi√≥n.
                       ‚úî Nodo de hoja / terminal: Los nodos sin hijos (sin 
                         divisi√≥n adicional) se llaman Hoja o nodo terminal.
    Partes de los 
    √Årboles de 
    Decisi√≥n
     ‚úî Poda (Pruning): Consiste en la reducci√≥n del 
       tama√±o de los √°rboles de decisi√≥n eliminando 
       nodos.
     ‚úî Rama / Sub√°rbol: Una subsecci√≥n del √°rbol de 
       decisi√≥n se denomina rama o sub√°rbol.
     ‚úî Nodo padre e hijo: Un nodo, que se divide en 
       subnodos se denomina nodo principal de 
       subnodos, mientras que los subnodos son hijos de 
       un nodo principal.
                        REEMPLAZAR 
                        POR IMAGEN
       Ventajas y 
      desventajas
    Ventajas
     ‚úî Caja blanca (conjunto de reglas con 
       booleanos), sus resultados son f√°ciles de 
       entender e interpretar.
     ‚úî Relativamente robusto cuando la complejidad 
       no es tan alta.
     ‚úî Funcionan relativamente bien con grandes 
       conjuntos de datos.
     ‚úî Combinaciones de los mismos pueden dar 
       resultados muy certeros sin perder 
       explicabilidad, por ejemplo, Random Forest.
                       Desventajas
                       ‚úî Tienden al sobreajuste u overfitting de los datos, 
                         por lo que el modelo al predecir nuevos casos no 
                         estima con el mismo √≠ndice de acierto.
                       ‚úî Se ven influenciadas por los outliers, creando 
                         √°rboles con ramas muy profundas que no 
                         predicen bien para nuevos casos. 
                       ‚úî Crear √°rboles demasiado complejos puede 
                         conllevar que no se adapten bien a los nuevos 
                         datos.
                       ‚úî Se pueden crear √°rboles sesgados si una de las 
                         clases es m√°s numerosa que otra es decir, si hay 
                         desbalance de clases.
      Ejemplos de 
       aplicaci√≥n
       √Årboles de decisi√≥n- 
       Variables num√©ricas
       Exploremos una nueva idea de como 
       hacer una clasificaci√≥n de la siguiente 
       forma:
        1.  Tomar un atributo, aplicar una 
            condici√≥n
        2.  Seleccionar otro atributo y chequear 
            condici√≥n
        3.  En las hojas tendremos la asignaci√≥n 
            final
        4.  Aplicar el m√©todo con cu√°ntas 
            variables se desee
  √Årboles de decisi√≥n- 
  Variables l√≥gicas
    √Årboles de decisi√≥n- 
    Variables categ√≥ricas
     ‚úî Este √°rbol de decisi√≥n se 
       fundamenta en decidir si se espera o 
       no.
     ‚úî Los nodos internos representan los 
       atributos testeados
     ‚úî Branching (creaci√≥n de nivel) se 
       realiza de acuerdo con los valores de 
       los atributos
     ‚úî Los leaf nodes representan los 
       outputs (Asignaci√≥n de clases)
  √Årboles de decisi√≥n- 
  Aplicaci√≥n
 Ejemplo
 Ejemplo
      from matplotlib import pyplot as plt
      from sklearn import datasets
      from sklearn.tree import DecisionTreeClassifier
      from sklearn import tree
      # Cargar los datos
      iris = datasets.load_iris()
      X = iris.data
      y = iris.target
      # ajustar arbol de decisi√≥n simple con 
      hiperparametros (defecto)
      clf = DecisionTreeClassifier(random_state=1234)
      model = clf.fit(X, y)
      # Graficando
      fig = plt.figure(figsize=(18,10))
      _ = 
      tree.plot_tree(clf,feature_names=iris.feature_names, 
                        class_names=iris.target_names,
                        filled=True)
 Ejemplo
      from dtreeviz.trees import dtreeviz
      # Una forma diferente de ver el arbol
      viz = dtreeviz(clf, X, y,
                     target_name="target",
                     feature_names=iris.feature_names,
                     class_names=list(iris.target_names))
      viz.save("decision_tree.svg") # Guardar la imagen
      viz
      En este caso adem√°s de mostrarnos las 
      divisiones nos proporciona la cantidad de 
      individuos en cada categor√≠a as√≠ como su 
      ubicaci√≥n en la distribuci√≥n de la variable.
                 ‚òï
               Break
               ¬°10 minutos y 
                volvemos!
     KNN: K-Nearest-
    Neighbor (Vecinos 
       cercanos)
    KNN
    Puede usarse para clasificar nuevas muestras (valores 
    discretos) o para predecir (regresi√≥n, valores 
    continuos). 
    Sirve esencialmente para clasificar valores, buscando 
    los puntos de datos ‚Äúm√°s similares‚Äù (por cercan√≠a).
       KNN
                                                                   2
                                                                    
        Entonces, supongamos el siguiente escenario: Tenemos       e
                                                                   r
        un Dataset con 2 Features, en el cual cada instancia       u
                                                                   t
        puede pertenecer a una de dos clases: ‚ÄúRojo‚Äù o ‚ÄúAzul‚Äù.     a
                                                                   e
                                                                   F
                                                                           Feature 1
       KNN
                                                                                         ?
                                                                  2
                                                                   
                                                                  e
        Dada una nueva instancia, de la cual no sabemos cu√°l      r
                                                                  u
        es  su clase, vamos a recurrir a sus vecinos cercanos     t
        para clasificarla. La pregunta ser√≠a entonces, ¬øLa        a
                                                                  e
        clasificamos como rojo o como azul?                       F
                                                                          Feature 1
       KNN                                                                k = 
                                                                          1       ?
                                                           2
        Si tomamos K=1, solo miraremos al vecino m√°s        
                                                           e
        cercano.                                           r
                                                           u
                                                           t
                                                           a
        Aclaraci√≥n: K es el nro de vecinos.                e
                                                           F
                           Azul
        KNN                                                                        k = 
                                                                                   3       ?
                                                                   2
                                                                    
                                                                   e
        Si elegimos otro valor de k, por ejemplo k > 1, nuestra    r
                                                                   u
        clasificaci√≥n cambiar√° significativamente.                 t
                                                                   a
                                                                   e
        Por ejemplo, con k = 3 tenemos dos vecinos Rojos y         F
        uno Azul. Por lo tanto en base a este escenario, la 
        clasificaci√≥n ser√°: Rojo.
                                                                            Feature 1
       Para pensar
   ¬øQu√© ventajas y desventajas creen que 
   puede tener esta metodolog√≠a a la hora de 
   hacer clasificaciones con muchos y pocos 
   datos?.
   Contesta mediante el chat de Zoom 
    import matplotlib.pyplot as plt
    import pandas as pd
    from sklearn import datasets, neighbors
    from mlxtend.plotting import plot_decision_regions
    def knn_comparison(data, k): # funcion de comparacion
    x = data[['X','Y']].values # Extraccion de columns
    y = data['class'].astype(int).values # Clase y como int
    clf = neighbors.KNeighborsClassifier(n_neighbors=k) #algoritmo
    clf.fit(x, y)# Graficar la region de decision
    plot_decision_regions(x, y, clf=clf, legend=2)# A√±adir 
    anotaciones
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.title('Knn with K='+ str(k))                       Datos tipo: Estructura de agrupamiento 
    plt.show()
    # Cargar y aplicar funcion                             en forma de u
    data1 = pd.read_csv('ushape.csv')
    for i in [1,5,20,30,40,80]: # Para diferentes valores de k (Knn)
       knn_comparison(data1, i)
    import matplotlib.pyplot as plt
    import pandas as pd
    from sklearn import datasets, neighbors
    from mlxtend.plotting import plot_decision_regions
    # Data concentrica
    data2 = pd.read_csv('concertriccir2.csv')
    for i in [1,5,20,30,40,60]:
       knn_comparison(data2, i)
                                                                  Datos tipo: Estructura de 
                                                                  agrupamiento conc√©ntricas.
   import matplotlib.pyplot as plt
   import pandas as pd
   from sklearn import datasets, neighbors
   from mlxtend.plotting import plot_decision_regions
   # Data XOR
   data3 = pd.read_csv('xor.csv')
   for i in [1,5,20,30,40,60]:
     knn_comparison(data3, i)
                                                             Datos tipo: Estructura de 
                                                             agrupamiento XOR con formas 
                                                             no lineales.
   import matplotlib.pyplot as plt
   import pandas as pd
   from sklearn import datasets, neighbors
   from mlxtend.plotting import plot_decision_regions
   # Linear separable
   data4 = pd.read_csv('linearsep.csv')
   for i in [1,5,20,30,40,60]:
      knn_comparison(data4, i)
                                                 Datos tipo: Estructura de 
                                                 agrupamiento lineal separable.
   import matplotlib.pyplot as plt
   import pandas as pd
   from sklearn import datasets, neighbors
   from mlxtend.plotting import plot_decision_regions
   # Data outliers
   data5 = pd.read_csv('outlier.csv')
   for i in [1, 5,20,30,40,60]:
      knn_comparison(data5, i)
                                                 Datos tipo: Estructura de 
                                                 agrupamiento con outliers.
    Consideracione
    s
     1. En todos los casos vemos que si elegimos k=1 
      se tiene un modelo con overfit.
     2. Cuando el valor es muy grande de k (e.g 60) 
      tenemos un modelo con underfit excepto 
      cuando tenemos outliers y en formas como 
      XOR no lineales
     3. Cada dataset tiene su propio requerimiento 
      para el valor de k 
     4. Valores altos de k pueden llevar a alto costo 
      computacional
     5. Cuando k es peque√±o tenemos bajo sesgo pero 
      alta varianza. Valores altos de k generan 
      menor varianza pero mayor sesgo
    Regresi√≥n log√≠stica
  Regresi√≥n log√≠stica
  T√©cnica de aprendizaje autom√°tico que 
  proviene del campo de la estad√≠stica. A 
  pesar de su nombre no es un algoritmo, 
  sino que es un m√©todo para problemas de 
  clasificaci√≥n, en los que se obtienen un 
  valor binario entre 0 y 1.
       Definici√≥n
         ‚úî Es un modelo estad√≠stico que se 
             utiliza para determinar si una               ‚úî Depende de la definici√≥n de un 
             variable independiente tiene un                  umbral para distinguir las clases 
             efecto sobre una variable                        binarias (por ejemplo, <50% mal 
             dependiente binaria (Clasificaci√≥n).             escrito = no es spam,> 50% mal 
         ‚úî Usualmente solo hay dos resultados                 escrito = spam). 
             potenciales.
    Un problema de clasificaci√≥n es identificar 
    si una operaci√≥n dada es fraudulenta o 
    no, asoci√°ndose una etiqueta ‚Äúfraude‚Äù a 
    unos registros y ‚Äúno fraude‚Äù a otros. 
    Entonces, la Regresi√≥n Log√≠stica describe 
    y estima la relaci√≥n entre una variable 
    binaria dependiente y las variables 
    independientes. 
                                                           Ejemplo
     En general, este algoritmo se puede 
     utilizar para varios problemas de 
     clasificaci√≥n, como la detecci√≥n de spam, 
     predicci√≥n de la diabetes, si un cliente 
     determinado comprar√° un producto en 
     particular o si se ir√° con la competencia, 
     hay muchos m√°s ejemplos en donde se 
     puede aplicar este algoritmo. 
                                               Matem√°tica involucrada
      ‚úî Lleva el nombre de la funci√≥n 
        utilizada en el n√∫cleo del m√©todo, la 
        Funci√≥n Log√≠stica es tambi√©n 
        llamada funci√≥n Sigmoide. 
      ‚úî Esta funci√≥n es una curva en forma 
        de S que puede tomar cualquier 
        n√∫mero de valor real y asignar a un 
        valor entre 0 y 1. 
      ‚úî La ecuaci√≥n que define la funci√≥n 
        sigmoide es la siguiente:
                                               Matem√°tica involucrada
      ‚úî Si la curva va a infinito positivo la 
        predicci√≥n se convertir√° en 1, y si la 
        curva pasa el infinito negativo, la 
        predicci√≥n se convertir√° en 0. 
      ‚úî Si la salida de la funci√≥n Sigmoide es 
        mayor que 0.5, podemos clasificar el 
        resultado como 1 o SI, y si es menor 
        que 0.5 podemos clasificarlo como 0 
        o NO. 
                                                           Matem√°tica involucrada
      Por  su  parte  si  el  resultado  es  0.75, 
      podemos   decir  en   t√©rminos   de 
      probabilidad  como,  hay  un  75%  de 
      probabilidades  de  que  el  paciente  sufra 
      c√°ncer.
                                                        Cuando usar o no la Regresi√≥n Log√≠stica
                Regresi√≥n  log√≠stica  para    K=2  clases.          Regresi√≥n  log√≠stica  para    K=3  clases.  Se 
                Siempre  nos  dar√°  un  l√≠mite  de  decisi√≥n        introduce a la data train una tercera clase 
                lineal. Los puntos rojos y verdes representan       denotada por el color azul. A pesar de que 
                el training data de las diferentes clases y         ahora  hay  m√°s  de  dos  clases  las 
                la intersecci√≥n entre los campos rojo y verde       regiones  de  decisi√≥n  entre  cualquier 
                representan el decisi√≥n boundary obtenido           pareja de clases sigue siendo LINEAL.
                de la regresi√≥n log√≠stica aprendiendo desde 
                la data. 
   Aprendizaje supervisado / 
   Clasificaci√≥n
   ¬øLos Algoritmos de Clasificaci√≥n como 
   √Årboles de Decisi√≥n, KNN y la Regresi√≥n 
   Log√≠stica son los √∫nicos que existen? ¬°Por 
   supuesto que no! 
   Existen muchos m√°s como ser por ejemplo: 
   Support Vector Machines (SVM), Random Forest, entre 
   otros. 
                                                                                                                  Ejemplo
     from sklearn.datasets import load_breast_cancer
     from sklearn.linear_model import LogisticRegression
     from sklearn.metrics import accuracy_score
     from sklearn.model_selection import train_test_split
     X, y = load_breast_cancer(return_X_y=True)
     # Separacion train/tet
     X_train, X_test, y_train, y_test = train_test_split(X, y)
     model = LogisticRegression(max_iter=10000, n_jobs=-1)
     # Ajustar modelo
     model.fit(X_train, y_train)
     #Predicciones
     predicciones = model.predict(X_test)
     from sklearn.metrics import confusion_matrix
     cf_matrix = confusion_matrix(y_test, predicciones)
     import seaborn as sns
     ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')                  Obtenemos un accuracy de 97% lo 
     ax.set_title('Matriz de confusion con labels\n\n');                    cual es bastante bueno en primera 
     ax.set_xlabel('\nValores predichos')                                   medida para un modelo simple!
     ax.set_ylabel('Valores reales ');
     ax.xaxis.set_ticklabels(['False','True'])
     ax.yaxis.set_ticklabels(['False','True']);plt.show()
       Regresi√≥n
 Problemas de regresi√≥n
        ‚úî Reconocen  las  estructuras  matem√°ticas  y 
          relaciones  dentro  del  conjunto  de  datos  para 
          obtener conclusiones sobre la distribuci√≥n de una 
          variable num√©rica. 
        ‚úî Los  algoritmos  de  clasificaci√≥n  comunes  son 
          clasificadores  lineales,  m√°quinas  de  vectores  de 
          soporte  (SVM),  √°rboles  de  decisi√≥n,  k-nearest 
          Neighbor y Random Forest
 Tipos de Problemas en regresi√≥n
     ‚úî Tenemos dos grandes tipos: problemas lineales y 
       no lineales
     ‚úî Problemas  lineales:  son  aquellos  donde  los 
       coeficientes que acompa√±an a las variables del 
       modelo son lineales
     ‚úî Problemas no lineales: son todos aquellos en 
       donde  no  se  cumple  el  supuesto  del  modelo 
       lineal,  por  ejemplo  una  serie  de  Fourier  o  de 
       crecimiento Weibull
 Ejemplos Problemas de Regresi√≥n
         ‚úî Predicci√≥n comportamiento de clientes
         ‚úî Pron√≥sticos de demanda
         ‚úî Pron√≥stico de Revenue y Profit
         ‚úî Cantidad de demanda 
         ‚úî Eficiencia de operaciones
         ‚úî Optimizaci√≥n de tiempos para procesos
         ‚úî Soporte de decisiones
         ‚úî Correcci√≥n de errores
         ‚úî An√°lisis preventivo y correctivo
         ‚úî Evaluaci√≥n de riesgo
    Tipos de algoritmos 
      para regresi√≥n
 Tipos de algoritmos para regresi√≥n
                        Algoritmos        Abreviaci√≥n   Muestras 
                                                       ponderadas?
                     Linear Regression       LR            No
                     Ridge Regression        RR            Si
                     Lasso Regression        LR            Si
                   Support Vector Machine    SVM           Si
                        AdaBoost             AB            Si
                    Elastic Net Regression   ENR           Si
                      Decision Trees         DT            No
      Fuente: Adaptado de Woubishet Zewdu. (2020).
      En Morado algoritmos m√°s populares 
  Tipos de algoritmos para regresi√≥n
                             Algoritmos            Abreviaci√≥       Muestras 
                                                        n         ponderadas?
                        Polynomial Regression          LRC             Si
                        Multi-layer Perceptron        MLPR             No
                             Regression
                         Stochastic Gradient          SGD              Si
                             Descending
                     Gaussian Process Regression      GPR              No
                              LightGBM                QDA              Si
                      Random Forest Regression         RFC             Si
                              XGBOOST                 XGB              Si
       Fuente: Adaptado de Woubishet Zewdu. (2020).
       En Morado algoritmos m√°s populares 
    Aprendizaje supervisado / 
    Regresi√≥n
    Los algoritmos de Regresi√≥n, intentan 
    predecir una variable de tipo num√©rica o 
    cuantitativa como por ejemplo: 
    ¬øCu√°nto crees que vale esta casa?
            Regresi√≥n Simple              Regresi√≥n 
                                           M√∫ltiple
    Aprendizaje supervisado / 
    Regresi√≥n
                   ¬øCu√°nto crees que vale esta casa?
       $ 70,000           ‚ùì             $ 160,000
    Aprendizaje supervisado / 
    Regresi√≥n
    El precio de una casa:
    Aprendizaje supervisado / 
    Regresi√≥n
    El precio de una casa:
    Aprendizaje supervisado / 
    Regresi√≥n
    El precio de una casa:
      Actividad colaborativa
   ¬°Llevemos lo visto hasta el momento a la 
   acci√≥n!
   Les proponemos que puedan realizar la 
   siguiente actividad.
   Duraci√≥n: 15 minutos
             ACTIVIDAD COLABORATIVA
        Acuerdos
       Presencia                                       Apertura al aprendizaje
        ‚úì Participar y ‚Äúestar‚Äù en la clase, que          ‚úì Siempre, pero siempre puedes 
            tu alrededor no te distraiga                    seguir aprendiendo. Compartir el 
                                                            conocimiento es v√°lido, la 
       Escucha activa                                       construcci√≥n colaborativa es la 
                                                            propuesta.
        ‚úì Escuchar m√°s all√° de lo que la 
            persona est√° expresando                    Todas las voces
            directamente
                                                         ‚úì Escuchar a todos, todos podemos 
                                                            reflexionar. Dejar el espacio para 
                                                            que todos podamos participar.
            ACTIVIDAD COLABORATIVA
       Modelo de regresi√≥n en 
       acciones
       Consigna: Utilizaremos informaci√≥n de       Realizaremos la actividad en grupos de 3-
       precios de acciones y las medidas de        4 personas 
       volatilidad y retorno para crear un modelo 
       de regresi√≥n                                Tiempo: 15 minutos
       NOTA: usaremos los breakouts rooms. El tutor/a tendr√° el rol de facilitador/a.
       ACTIVIDAD COLABORATIVA
    Modelo de regresi√≥n en 
    acciones
     ‚úî Cargar por medio de un ciclo for en un solo dataframe los precios de las siguientes 
       acciones  en  la  carpeta  de  la  clase:  Dominion  Energy  Inc.  (D),  Exelon  Corp.  (EXC). 
       NextEra Energy Inc. (NEE), Southern Co. (SO), Duke Energy Corp. (DUK)
     ‚úî Calcular volatilidad relativa (High-Low)/Open y el √≠ndice de retorno por medio de la 
       f√≥rmula: (Close/Open)-1 
     ‚úî Crear  un  modelo  regresi√≥n  usando  como  variable  dependiente  (Volatilidad 
       relativa)  e  independientes  (Open,  High,  Low,  Close,  Volume_Millions  y 
       Symbol)
     ‚úî Crear un modelo regresi√≥n usando como variable dependiente (√çndice de retorno) 
       e independientes (Open, High, Low, Close, Volume_Millions y Symbol)
     ‚úî Interpretar resultado.
       CLASE N¬∞14
       Glosario
        Aprendizaje Supervisado: subcategor√≠a del             √Årboles de decisi√≥n: estructuras 
        aprendizaje autom√°tico y la inteligencia artificial   matem√°ticas tipo if-else que se construyen con 
        que cuenta con datos etiquetados (hist√≥ricos) para    criterios de impureza (gini, entrop√≠a) y que 
        aprender de comportamiento de una variable            permiten entender el comportamiento de 
        particular.                                           variables categ√≥ricas o num√©ricas. Son 
                                                              sencillos de interpretar pero puede llegar a 
        Problemas de clasificaci√≥n: son aquellos donde        tener mucho overfitting.
        la variable respuesta es una categor√≠a (e.g 
        predicci√≥n de fraude), puede ser binario o            KNN (K nearest neighbor): t√©cnica de 
        multiclase.                                           clasificaci√≥n que se fundamenta en distancias 
                                                              para encontrar pertenencia a categor√≠as 
        Problema de regresi√≥n: son aquellos donde la          determinadas.
        variable respuesta es una variable continua (e.g 
        predicci√≥n de ventas).                                Regresi√≥n log√≠stica: t√©cnica de clasificaci√≥n 
                                                              que utiliza como fundamento matem√°tico la 
                                                              funci√≥n sigmoide para encontrar probabilidad 
                                                              de poseer una caracter√≠stica determinada.
      ¬øPreguntas?
                   Resumen 
               de la clase hoy
              ‚úì Aprendizaje Supervisado.
              ‚úì Algoritmos de Clasificaci√≥n.
              ‚úì Algoritmos de Regresi√≥n.
      Opina y valora 
       esta clase
        Muchas 
        gracias.
