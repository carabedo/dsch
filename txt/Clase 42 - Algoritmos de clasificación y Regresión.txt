    Esta clase va a ser
        grabad
          a
              Clase 42. DATA SCIENCE
             Algoritmos de 
             clasificaciÃ³n y 
               RegresiÃ³n
      Temario
                       41                      42                     43
                 Algoritmos de           Algoritmos de           Algoritmos de 
                  clasificaciÃ³n          clasificaciÃ³n y          AgrupaciÃ³n I
                                           RegresiÃ³n
                                       âœ“ SVM                     âœ“ K means
                âœ“ KNN                  âœ“ Ejemplos clasificaciÃ³n 
                âœ“ Random Forest           errÃ³nea                âœ“ DBSCAN
                âœ“ RegresiÃ³n            âœ“ RegresiÃ³n Lineal y 
                                          MÃºltiple
                   LogÃ­stica
                                       âœ“ OptimizaciÃ³n de 
                                          hiperparÃ¡metros
    Objetivos de la clase
                 Profundizar en el Aprendizaje Supervisado 
                 Aplicar el algoritmo de SVM
                 Aplicar los modelos de RegresiÃ³n
        MAPA DE CONCEPTOS
                                Ejemplos de 
                                clasificaciÃ³n 
                                 errÃ³nea
                             Algoritmos de              RegresiÃ³n 
           SVM               clasificaciÃ³n y            Lineal y 
                               regresiÃ³n                MÃºltiple
                                OptimizaciÃ³n 
                                 de hiper 
                                parÃ¡metros
      Support Vector 
        Machine:
          SVM
       DefiniciÃ³n
   MÃ¡quinas de soporte vectorial 
      SVM por sus siglas en inglÃ©s 
    (Support Vector Machines), es un 
     algoritmo que se puede usar tanto 
    para regresiÃ³n como para problemas 
    de clasificaciÃ³n. Es un algoritmo que 
    se fundamenta en la construcciÃ³n de 
      hiperplanos de segmentaciÃ³n.
     Ejemplo aplicado
        MÃ¡quinas de soporte vectorial 
         1) Imaginemos que tenemos dos grupos               2) Pero quÃ© pasa si tenemos un punto muy 
         (Verde y Rojo). La lÃ­nea naranja en este caso      cerca del lÃ­mite de decisiÃ³n
         funciona como punto lÃ­mite para decisiÃ³n
       MÃ¡quinas de soporte vectorial 
                                                               Podemos hacer esta 
                                                               clasificaciÃ³n de una mejor 
         3) En este caso lo podrÃ­amos clasificar como          forma?
         verde pero no tiene mucho sentido en este 
         caso
       Podemos enfocarnos en las observaciones       Para ello podemos usar el valor del punto 
       cerca a los lÃ­mites de los dos grupos         medio entre esos dos puntos
    MÃ¡quinas de soporte vectorial 
      TERMINOLOGÃA
                             Para recordar el margen en teorÃ­a 
                             debe ser igual en ambos lados del 
                             threshold para que se tenga una 
                             buena clasificaciÃ³n 
    La distancia mÃ¡s corta entre las 
    observaciones y el threshold se conoce como Pero no siempre funciona bien! 
    margen esto se conoce como Maximal 
    Margin Classifier        OUTLIERS
                             PORQUE EN ESTE CASO NO 
                             FUNCIONA?
       MÃ¡quinas de soporte vectorial 
       En este caso esa metodologÃ­a no             Elegir una zona lÃ­mite que no sea sensible 
       funciona tan bien y es porque los           a outliers se conoce como Bias/Variance 
       Maximal Margin Classifiers son muy          Tradeoff y el lÃ­mite se conoce como Soft 
       sensibles a OUTLIERS                        margin
                                                         Support Vector Classifier viene 
                                                         del hecho que se usÃ³ un soft 
                                                         margin por medio de support 
                                                         vectors
  MÃ¡quinas de soporte vectorial 
   MÃ¡quinas de soporte vectorial 
                         Las observaciones que 
                         quedan dentro del soft 
                         margin quedan mal 
                         clasificadas.
  MÃ¡quinas de soporte vectorial 
    MÃ¡quinas de soporte vectorial 
                               Cuando hay 4 o mÃ¡s 
                               dimensiones la mÃ¡quina 
                               de soporte vectorial es un 
                               hiperplano asÃ­ como en 
                               el caso 1D, 2D o 3D
    MÃ¡quinas de soporte vectorial 
                             Las mÃ¡quinas de soporte vectorial 
                             pueden manejar outliers y problemas de 
                             malas clasificaciones
     Ejemplo: QuÃ© pasarÃ­a si tuviÃ©ramos este caso en el cual los puntos verdes 
     representan pacientes recuperados y los rojo no recuperados (El medicamente solo 
     funciona en las dosis apropiadas)
    MÃ¡quinas de soporte vectorial 
    En estos casos Maximal Margin Classifiers no funciona tan bien y hablamos de SVM 
    (Support Vector Machines)
                                       1) Empezar con 
                                        data en una 
                                        dimensiÃ³n baja 
                                        (1D)
                                       2) Mover los datos 
                                        a una dimensiÃ³n 
                                        mayor (e.g 2D)
                                       3) Encontrar el SVC 
                                        que separe los 
                                        datos
      Ejemplos de 
    clasificaciÃ³n errÃ³nea
   Clasificaciones errÃ³neas
    Vamos a suponer que los puntos azules corresponden a la clase Â«azulÂ» y los 
    puntos rojos a la clase Â«rojoÂ».
    Ahora vamos a intentar dibujar una lÃ­nea 
    que separe los puntos azules de los rojos. 
    De esta forma, cuando haya un punto nuevo, intentaremos poder 
    determinar quÃ© color va a tener, dependiendo del lado de la lÃ­nea en el 
    que se encuentre.
             Algunos ejemplosâ€¦
                               En el contexto de los algoritmos de 
                               clasificaciÃ³n podemos tener 
                               muchos falsos positivos y 
                               negativos, es por eso que debemos 
                               tener mucho cuidado a la hora de 
                               usar cualquier algoritmo
                               A continuaciÃ³n veremos algunos 
                               ejemplos de formas equivocadas de 
                               clasificar
   Clasificaciones errÃ³neas
    En la siguiente figura, podemos decir que lo 
    que estÃ© a la izquierda de la lÃ­nea, es azul y 
    lo que estÃ© a la derecha, es rojo. 
    Sin embargo, el punto nuevo abajo a la 
    izquierda es clasificado como azul 
    aunque en realidad deberÃ­a clasificarse 
    como rojo.
   Clasificaciones errÃ³neas
    Podemos decir que cualquier punto que estÃ© 
    por arriba de la lÃ­nea establecida serÃ¡ azul y 
    cualquier otro punto que estÃ© por debajo de 
    la lÃ­nea serÃ¡ rojo. 
    Sin embargo, el nuevo punto a la 
    derecha, ha sido incorrectamente 
    clasificado como azul, cuando deberÃ­a 
    ser rojo.
   Clasificaciones errÃ³neas
    La lÃ­nea que mejor distingue las 
    zonas de los puntos azules de la 
    zona de los puntos rojos es la que 
    maximiza el margen entre ambos.
     SVM es una tÃ©cnica de machine 
    learning que encuentra la mejor 
    separaciÃ³n posible entre clases. 
      Para recordarâ€¦
   Resulta importante mencionar, que 
   normalmente los problemas de aprendizaje 
   automÃ¡tico tienen muchas dimensiones, por 
   lo tanto en vez de encontrar la lÃ­nea Ã³ptima, el 
   SVM encuentra el hiperplano que maximiza 
   el margen de separaciÃ³n entre clases 
     RegresiÃ³n Lineal 
     Simple y MÃºltiple
     RegresiÃ³n Lineal 
        Simple
   RegresiÃ³n Lineal simple
   A diferencia de los modelos anteriores, 
    es un modelo estadÃ­stico que trata 
   de explicar la relaciÃ³n que existe entre 
      una variable dependiente 
   (variable respuesta) y una variable 
     independiente (explicativa) 
   RegresiÃ³n Lineal simple
   El modelo de regresiÃ³n lineal estÃ¡ dado por la 
   siguiente expresiÃ³n:
            y=í¾ªí µ+í¾ªí µX +í¾ªí µ
   í¾ªí µ= intercepto (valor que toma Y cuando X 
   vale 0)
   í¾ªí µ= es la pendiente (indica cÃ³mo cambia Y al 
   incrementar X en una unidad)
   í¾ªí µ= representa el error aleatorio con una 
   distribuciÃ³n normal (0,í¾ªí µ)
   RegresiÃ³n Lineal simple
    La estimaciÃ³n de í¾ªí µ y í¾ªí µ se hace por medio del 
    metodo de minimos cuadrados, donde se 
    busca minimizar la suma de cuadrados de los 
    errores dada por:
   RegresiÃ³n Lineal simple
    InterpretaciÃ³n del coeficiente í¼·í µ
    Tenemos tres casos posibles:
     1. í¾ªí µ =0 para cualquier valor de X la variable 
      Y es constante (no cambia)
     2. í¾ªí µ >0 indica que al aumentar el valor de 
      X, tambiÃ©n aumenta el valor de Y
     3. í¾ªí µ<0 indica que al aumentar el valor de X, 
      el valor de Y disminuye
   RegresiÃ³n Lineal simple
    Coeficiente de correlaciÃ³n R: Es una 
    medida que trata de medir la dependencia 
    lineal que existe entre dos variables. Y su 
    cuadrado se determina coeficiente de 
    determinaciÃ³n R^2
    El coeficiente de determinaciÃ³n cuantifica el 
    porcentaje de variabilidad que puede explicar 
    X de Y, por ejemplo si R^2= 0.45, indica que 
    45% de la variabilidad de Y es explicada por X
    Propiedades del coeficiente de 
   RegresiÃ³n Lineal simple
    correlaciÃ³n
     1. No tiene dimensiÃ³n y siempre estÃ¡ entre 
      [-1,1]
     2. Si las variables son independientes 
      entonces R=0, pero lo inverso no 
      siempre es cierto
     3. Si existe relaciÃ³n lineal perfecta R=1 o -1 
      (relaciÃ³n inversa perfecta)
     4. Si R>0 indica una relaciÃ³n directa lineal 
      de X en Y
     5. Si R<0 indica una relacion inversa de X 
      en Y
   RegresiÃ³n Lineal simple
    Supuestos
     1. Independencia: los residuales deben 
      ser independientes entre sÃ­ 
     2. Homocedasticidad: significa varianzas 
      iguales, para cada valor de X la varianza 
      de los residuales debe ser la misma 
     3. Normalidad: para cada valor de X, los 
      residuales tienen distribuciÃ³n normal con 
      media cero 
     RegresiÃ³n Lineal 
       MÃºltiple
   RegresiÃ³n Lineal simple
    Similar al modelo estadÃ­stico de 
   RegresiÃ³n lineal simple donde trata 
   de explicar la relaciÃ³n que existe entre 
      una variable dependiente 
     (variable respuesta) y unas 
      variables independientes 
         (explicativas) 
   RegresiÃ³n Lineal simple
   El modelo de regresiÃ³n lineal mÃºltiple estÃ¡ 
   dado por la siguiente expresiÃ³n:
         y=í¾ªí µ+í¾ªí µ1X1+... +í¾ªí µnXn+í¾ªí µ
   í¾ªí µ= intercepto (valor que toma Y cuando X 
   vale 0)
   í¾ªí µi= es la pendiente de cada variable 
   independiente (i= 1,2,.....,n)
   í¾ªí µ= representa el error aleatorio con una 
   distribuciÃ³n normal (0,í¾ªí µ)
   RegresiÃ³n Lineal simple
   Este modelo al igual que el de regresiÃ³n lineal 
   simple tiene los mismos supuestos y se 
   puede cuantificar su desempeÃ±o de la misma 
   forma (utilizando el coeficiente de 
   determinaciÃ³n (R^2)
   De igual forma el la pendiente de cada 
   variable independiente puede ser o no 
   significativa y se necesita verificar 
   individualmente. 
     OptimizaciÃ³n de 
     hiperparametros
       DefiniciÃ³n
   Hiperparametros
   Los hiperparametros son variables que 
   rigen el proceso de entrenamiento (e.g en 
   una red neuronal las capas ocultas serÃ­an un 
   ejemplo). Estas variables no estÃ¡n 
   directamente relacionadas con los datos 
   de entrenamiento, sino que son de 
   configuraciÃ³n y por ende son constantes 
   durante cualquier entrenamiento
   Hiperparametros
   AdemÃ¡s de los hiperparametros tenemos dos 
   otros conceptos importantes que controlan el 
   entrenamiento de cualquier modelo:
   1. Datos de entrada: colecciÃ³n de 
   instancias con las caracterÃ­sticas relevantes 
   para el problema de interÃ©s. Se usan en el 
   entrenamiento para configurar el modelo con 
   el fin de que pueda realizar predicciones 
   sobre nuevas instancias 
   Hiperparametros
   AdemÃ¡s de los hiperparametros tenemos dos 
   otros conceptos importantes que controlan el 
   entrenamiento de cualquier modelo:
   2. ParÃ¡metros: son las variables que usan 
   los modelos para ajustarse a los datos (e.g los 
   nodos en una red neuronal y sus pesos). Los 
   parÃ¡metros son formalmente el modelo ya 
   que son los que dan las caracterÃ­sticas 
     Hypertuning de 
       parÃ¡metros
   Hypertuning de ParÃ¡metros
      Dentro de este contexto, resulta 
   importante entender que la optimizaciÃ³n 
      de hiper-parÃ¡metros, se realiza 
   normalmente mediante la utilizaciÃ³n de un 
     proceso de bÃºsqueda cuyo objetivo 
    consiste en encontrar la mejor selecciÃ³n 
   de valores para un conjunto finito de hiper-
    parÃ¡metros con el objetivo de generar el 
         mejor modelo posible.
                 â˜•
               Break
             Â¡10 minutos y 
             volvemos!
      Ejemplo en vivo
   Miraremos ejemplos de aplicaciÃ³n dentro 
   de la carpeta de clase para los algoritmos: 
   SVM, RegresiÃ³n Lineal + mÃºltiple. AdemÃ¡s 
   exploraremos cÃ³mo podemos hacer el 
   hypertuning de parÃ¡metros para un modelo 
   de RegresiÃ³n.
   Elaborando un algoritmo de 
             regresiÃ³n
      Utilizaremos lo aprendido en clase para crear un 
      modelo de regresiÃ³n y validar variables relevantes
             DuraciÃ³n: 15-20 mins
       ACTIVIDAD EN CLASE
    Elaborando un 
    algoritmo de 
    En esta oportunidad nos reuniremos en grupos de mÃ¡ximo 
    regresiÃ³n
    4 personas.
     1. Elegir 4 variables independientes que consideren 
       Ãºtiles para predecir los â€œcostosâ€ de nuevos clientes
     2. Realizar el Encoding de las variables independientes 
       (una persona hace el cÃ³digo y comparte, los demÃ¡s 
       ayudan dando instrucciones, etc.) para generar 
       matriz para el modelo
     3. Elegir uno de los modelos aprendidos en clase y 
       entrenarlo
     4. Generar una predicciÃ³n de costos sobre uno de los 
       estudiantes del grupo 
                                        1
                                        0
                     Entrenando un 
             algoritmo de Machine 
                            Learning
             DeberÃ¡s entregar el dÃ©cimo avance de tu proyecto final. Continuaremos hablando 
             sobre lo trabajado en la segunda pre entrega del proyecto final. CrearÃ¡s un 
             notebook donde trabajarÃ¡s sobre los datos elegidos en la primera y segunda pre 
             entrega del proyecto final. Posteriormente, realizarÃ¡s las etapas de: i) Encoding, ii) 
             IngenierÃ­a  de  atributos  y  iii)  Entrenamiento  de  un  modelo  de  Machine  Learning 
             Supervisado  (ClasificaciÃ³n  o  RegresiÃ³n)  o  no  supervisado  dependiendo  de  la 
             pregunta problema.
            DESAFÃO 
            ENTREGABLE
       Entrenando un algoritmo de Machine 
       Learning
       Consigna                                       Formato
         âœ“ Utilizar una fuente de datos para           âœ“ Se debe entregar un Jupyter notebook con 
            resolver problemas de clasificaciÃ³n o          el nombre: 
            regresiÃ³n.                                     â€œDesafio_AlgoritmoML_MVP_+Nombre
         âœ“ Realizar los procesos de Encoding,              _ +Apellido.ipynbâ€.
            Feature Engineering y entrenamiento       Sugerencias
            de un modelo de Machine Learning           âœ“ Se pueden utilizar fuentes de datos 
            (ClasificaciÃ³n o RegresiÃ³n)                    conocidas en sitios como Kaggle o UCI
       Aspectos a incluir                              âœ“ Se recomienda elegir datasets curados 
         âœ“ Notebook donde se detallen todos los            para que la mayor parte del tiempo se 
            pasos seguidos                                 utilice para el entrenamiento de modelos 
                                                           y no en limpieza de datos
       Ejemplo                                        ExplicaciÃ³n del desafÃ­o
         âœ“ Ejemplo DesafÃ­o Entrenamiento ML,           âœ“ Â¡Click aquÃ­!
     Â¿Quieres saber mÃ¡s?
     Te dejamos material 
     ampliado de la clase
         MATERIAL AMPLIADO
     Recursos multimedia
     Algoritmos de regresiÃ³n
      âœ“ Algoritmos de regresiÃ³n | Scikit-Learn | Enlace
      Disponible en nuestro repositorio.
      Â¿Preguntas?
       CLASE NÂ°42
       Glosario
       SVM: algoritmo de aprendizaje               ParÃ¡metros: son las variables que usan 
       supervisado que permite resolver            los modelos para ajustarse a los datos. Se 
       problemas de clasificaciÃ³n o regresiÃ³n      definen como la estructura interna del 
       haciendo uso de hiperplanos generando       modelos ya que son las caracterÃ­sticas del 
       regiones de separaciÃ³n con un amplio        mismo
       margen
                                                   Hiperparametros: variables que rigen el 
       RegresiÃ³n lineal: tÃ©cnica estadÃ­stica       proceso de entrenamiento, no estÃ¡n 
       que permite encontrar la asociaciÃ³n lineal  directamente relacionadas con los datos de 
       entre una variable dependiente (Y) y        entrenamiento sino que son de 
       una/varias variable(s) independiente(s)     configuraciÃ³n y por ende son constantes 
       llamadas Xâ€™s, puede ser simple (1 variable  durante cualquier entrenamiento 
       independiente) o mÃºltiple (mÃ¡s de 1 
       variable independiente)
        Muchas 
        gracias.
                   Resumen 
               de la clase hoy
              âœ“ ClasificaciÃ³n con SVM
              âœ“ Ejemplos de clasificaciÃ³n errÃ³nea
              âœ“ RegresiÃ³n Lineal simple y MÃºltiple
              âœ“ OptimizaciÃ³n de hiper parÃ¡metros 
      Opina y valora 
       esta clase
