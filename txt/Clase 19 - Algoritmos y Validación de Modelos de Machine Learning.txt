    Esta clase va a ser
        grabad
          a
              Clase 19. DATA SCIENCE 
             Algoritmos y 
            Validaci√≥n de 
        Modelos de Machine 
               Learning
      Temario
                      18                   19                    20
               Introducci√≥n al        Algoritmos y             Stack 
                ML y a la IA          validaci√≥n de         tecnol√≥gico I
                                     modelos de ML
                ‚úì Introducci√≥n         ‚úì Conceptos 
                ‚úì Tipos de IA             b√°sicos           ‚úì Base de 
                ‚úì Aplicaciones         ‚úì Aprendizaje           datos 
                   de la                  y validaci√≥n      ‚úì Lenguajes 
                   industria           ‚úì M√©tricas y            DS
                ‚úì Riesgos                 Evaluaci√≥n        ‚úì Visualizaci√≥n 
                   asociados
    Objetivos de la clase
                 Reconocer los conceptos b√°sicos asociados a 
                 Machine Learning.
                 Identificar las principales m√©tricas para 
                 evaluar la performance de un modelo.
        MAPA DE CONCEPTOS
                                    Historia de la 
                                    IA
                                    Clasificaci√≥n 
                  ML e 
                Inteligencia        IA y Rob√≥tica   RPA
                 Artificial
                                    IA en industrias
                                     Programas y 
                                      Algoritmos
                                       GPT - 3
  Repaso 
              MAPA DE CONCEPTOS                            Algoritmos y 
                                                          Validaci√≥n de 
                                                       Modelos de Machine 
                                                             Learning
                   Conceptos                Aprendizaje y               Aprendizaje y                M√©tricas y 
                    b√°sicos                   Validaci√≥n                  Validaci√≥n                modelos de 
                                                                                                     regresi√≥n
                 Dataset                    Overfitting                Matriz de                   RMSE
                                                                       confusi√≥n
                 Registro                   Underfitting               Exactitud                   MAE
                 Atributo                                              Precisi√≥n                   R2
                 Objetivo                                              Sensibilidad
                 Ingenier√≠a de                                         Especificidad
                 Factores
                 Outliers                                              F1 - Score
       PARA RECORDAR
    Inteligencia Artificial
    La evaluaci√≥n de modelos es un aspecto 
    fundamental y cr√≠tico en todo flujo de Data 
    Science. Pero antes de hablar de m√©tricas 
    de performance, resulta importante 
    entender algunos conceptos b√°sicos y 
    esenciales del Machine Learning. 
    EmpecemosÌ∏ÉÌ†Ω
    Conceptos b√°sicos
    Dataset, instancia, 
     caracter√≠stica y 
     variable objetivo
    Dataset: 
    conjunto 
     ‚úì Materia prima del sistema de 
    de datos
       predicci√≥n. 
     ‚úì Hist√≥rico de datos que se usa para 
       entrenar al sistema que detecta los 
       patrones. 
     ‚úì El conjunto de datos se compone de 
       instancias de factores, 
       caracter√≠sticas o propiedades.
    Instancia
      ‚úì Cada uno de los datos de los que se 
        disponen para hacer un an√°lisis. 
      ‚úì Cada instancia a su vez, est√° 
        compuesta de caracter√≠sticas que la 
        describen.
      ‚úì En una hoja de c√°lculo, las 
        instancias ser√≠an las filas; las 
        caracter√≠sticas, las columnas.
    Caracter√≠sticas
    ‚úì Atributos que describen 
      cada una de las instancias 
      del conjunto de datos. 
    ‚úì En una hoja de c√°lculo, 
      ser√≠an las columnas.
     Variable objetivo
     Atributo o factor que queremos predecir, el 
     objetivo de la predicci√≥n, como puede ser la 
     probabilidad de reingreso de un paciente tras 
     una intervenci√≥n quir√∫rgica.
      Ingenier√≠a de 
        factores
       (Feature 
      Engineering)
     Ingenier√≠a de Factores
     ‚úì Proceso previo a la creaci√≥n del 
       modelo en el que se hace an√°lisis, 
       limpieza y estructuraci√≥n de los datos. 
     ‚úì El objetivo es eliminar los campos que 
       no sirven para hacer la predicci√≥n y 
       organizarlos adecuadamente para que 
       el modelo no reciba informaci√≥n que 
       no le es √∫til y que podr√≠a provocar 
       predicciones de poca calidad o 
       confianza. 
     Ì±âÌ†Ω Este proceso es uno de los m√°s 
     importantes y m√°s costosos del proceso de 
     predicci√≥n. 
       Datos perdidos
         ‚úì Es muy habitual encontrarnos con valores      Pero ¬øqu√© podemos hacer en estos 
            perdidos en estos procesos.                  casos? Existen m√∫ltiples t√©cnicas para 
         ‚úì Pueden aparecer de distintas formas:          tratar los valores missing, lo veremos 
            como un signo de interrogaci√≥n, o N/A,       m√°s adelante en curso Ì∏ÉÌ†Ω
            como un 0 o simplemente como una celda 
            en blanco, pero en su mayor√≠a nos lo 
            encontramos representado como NaN que 
            se refiere a ‚Äúno un n√∫mero‚Äù. 
    ¬øQu√© es un outlier?
    Valores extremos
     Valor que no se corresponde con el patr√≥n 
     general de nuestros datos. Puede ser bueno, 
     malo o simplemente un error de datos pero en 
     todos esos casos tenemos que realizar un 
     an√°lisis.
    ¬øPor qu√© es 
    importante tratar los 
    outliers?
     En t√©rminos generales, tratar los outliers suele 
     mejorar los modelos de ML. 
     Muchos modelos avanzados son sensibles a los 
     valores extremos y adem√°s, siempre es preferible 
     realizar una buena preparaci√≥n de datos antes 
     que complejizar los modelos.
       Para pensar
   ¬øC√≥mo podemos evaluar si nuestro modelo 
   est√° aprendiendo correctamente de 
   nuestros datos?¬øPor qu√© es necesario usar 
   nuevas instancias y no limitarse a aquellas 
   con las que se entren√≥ el modelo? 
   Contesta mediante el chat de Zoom 
     Evaluaci√≥n del modelo
     ¬øC√≥mo podemos evaluar si 
     nuestro modelo est√° aprendiendo 
     correctamente de nuestros datos?
     Ì±âÌ†Ω Una respuesta posible ser√≠a, que para 
     evaluar si nuestro modelo aprendi√≥ o no 
     de nuestro datos, observemos su 
     desempe√±o o performance frente a 
     nuevas instancias es decir, frente a datos 
     que nunca vio. 
    Nuevas instancias
    ¬øPor qu√© es necesario usar nuevas 
    instancias y no s√≥lo aquellas con las que 
    se entren√≥ el modelo?
    La respuesta es sencilla, por que no se puede 
    ser ‚ÄúJuez y parte‚Äù al mismo tiempo. Ì∏ÖÌ†Ω
    A partir de este concepto, surgen las 
    siguientes caracter√≠sticas en ML: 
    ‚ÄúEntrenamiento‚Äù y ‚ÄúValidaci√≥n‚Äù para luego 
    hablar del ‚ÄúSobreajuste‚Äù o ‚ÄúSub-ajuste‚Äù. 
       Ejemplo en vivo
   ¬øC√≥mo podr√≠amos utilizar el feature engineering para 
   encontrar las variables m√°s relevantes en los precios 
   de inmuebles?
   Estudiaremos un ejemplo aplicado donde podremos 
   ver el uso de feature selection enfocado en Wrapper 
   Methods (forward, backward y stepwise)
   Utilizaremos el notebook  Clase_19.ipynb 
   dentro de la carpeta de clase.
      Aprendizaje y 
      Validaci√≥n   
     Entrenamiento y 
       validaci√≥n
    Nuevas instancias
    ¬øPor qu√© es necesario usar nuevas 
    instancias y no s√≥lo aquellas con las que 
    se entren√≥ el modelo?
    La respuesta es sencilla, por que no se puede 
    ser ‚ÄúJuez y parte‚Äù al mismo tiempo. Ì∏ÖÌ†Ω
    A partir de este concepto, surgen las 
    siguientes caracter√≠sticas en ML: 
    ‚ÄúEntrenamiento‚Äù y ‚ÄúValidaci√≥n‚Äù para luego 
    hablar del ‚ÄúSobreajuste‚Äù o ‚ÄúSub-ajuste‚Äù. 
     Aprendizaje o 
     Entrenamiento
    ‚úì Proceso en el que se detectan los 
      patrones de un conjunto de datos, 
      es decir, es el coraz√≥n del machine 
      learning. 
    ‚úì Cuando identificamos los patrones, se 
      pueden hacer predicciones con 
      nuevos datos que se incorporen al 
      sistema.
       Para pensar
   ¬øC√≥mo podemos utilizar la informaci√≥n de 
   la compra de libros, por ejemplo, respecto 
   al comportamiento de los clientes para 
   mejorar las utilidades del negocio? 
   Contesta mediante el chat de Zoom 
     Ejemplo
     Los datos de las compras de libros 
     online se pueden usar para analizar el 
     comportamiento de los clientes en sus 
     procesos de compra (t√≠tulos visitados, 
     categor√≠as, historial de compras, etc) 
     agruparlos en patrones de 
     comportamiento y hacer 
     recomendaciones de compra.
     Validaci√≥n
     ‚úì Proceso de evaluar un modelo 
       entrenado sobre un conjunto de datos 
       de prueba. Esto proporciona la capacidad 
       de generalizaci√≥n de un modelo de ML. 
     ‚úì Para poder evaluarlo correctamente, hay 
       que realizar ‚Äúsplit de datos‚Äù es decir, 
       separar nuestro dataset original en 
       ‚ÄúDatos de Entrenamiento‚Äù, que ser√°n 
       usados justamente para entrenar a nuestro 
       modelo y en ‚ÄúDatos de Test o de 
       Testing‚Äù que ser√°n aquellos datos que 
       utilizaremos para evaluar la performance 
       de nuestro modelo. 
    ¬øQu√© porcentaje se usa 
    para train y test? 
      Ì±âÌ†Ω No existe una √∫nica respuesta, en t√©rminos generales se suele utilizar un 70 % 
      de nuestros datos para el training y un 30 % para el testing.  
    ¬øQu√© porcentaje se 
    usa para train y 
    test? 
     Training : Datos para ajustar el modelo
     Validation: Datos para proporcionar una 
     evaluaci√≥n imparcial de un modelo que se 
     ajusta al conjunto de datos de entrenamiento 
     mientras se ajustan los hiper par√°metros del 
     modelo. 
     Test: Datos para proporcionar una evaluaci√≥n 
     imparcial de un modelo final que se ajusta al 
     conjunto de datos de entrenamiento.
     Validaci√≥n Cruzada
     ‚úì Tambi√©n conocida como Cross-
       Validation, separa los datos en 
       diferentes particiones y obtiene la media 
       de las evaluaciones de las distintas 
       particiones. 
     ‚úì Ayuda a evaluar los resultados que 
       devuelve el modelo y garantizar la 
       independencia de las particiones que 
       hacemos, con lo cual se evita el 
       sobreajuste.  
      Overfitting y 
      Underfitting
       Para pensar
   Considerando los siguientes 3 escenarios, 
   ¬øqu√© modelo parece ser el mejor?
   Contesta mediante el chat de Zoom 
   Overfitting y Underfitting
    El modelo a es muy simple y no reproduce correctamente la frontera 
    entre las clases. Esto se conoce como Underfitting o Sub-Ajuste.
      Overfitting y Underfitting
         El modelo a es muy simple  El modelo b tiene la 
         y no reproduce               complejidad suficiente para 
         correctamente la frontera    encontrar una frontera que 
         entre las clases. Esto se    parece ser la apropiada 
         conoce como Underfitting     en base al dataset 
         o Sub-Ajuste.                analizado.
      Overfitting y Underfitting
         El modelo a es muy simple  El modelo b tiene la              El modelo c se adapt√≥ 
         y no reproduce                 complejidad suficiente para   demasiado a los datos con los 
         correctamente la frontera      encontrar una frontera que    que fue entrenado. Esto se 
         entre las clases. Esto se      parece ser la apropiada       conoce como Overfitting o 
         conoce como Underfitting       en base al dataset            Sobre ‚Äì Ajuste.
         o Sub-Ajuste.                  analizado.
      Overfitting y Underfitting
         ‚úì Las principales causantes de obtener        ‚úì Tanto el Over como el Under ‚Äì Fitting, 
             malos resultados en Machine Learning         se relacionan al fallo de nuestro 
             son el Overfitting o el Underfitting         modelo al generalizar -encajar- el 
             de los datos. Dado que cuando                conocimiento que pretend√≠amos que 
             entrenamos nuestro modelo intentamos         adquieran.
             ‚Äúhacer encajar‚Äù -fit en ingl√©s- los datos 
             de entrada entre ellos y con la salida. 
    ¬øC√≥mo prevenir el 
    ‚úì Sucede cuando nuestro modelo aprende los datos de train 
    Overfitting?
      perfectamente, por lo que no es capaz de generalizar y 
      cuando le lleguen nuevos datos obtiene p√©simos resultados. 
      Ì∏≤Ì†Ω
    ‚úì Existen diferentes formas de prevenir el Overfitting: 
       ‚óã Dividir nuestros datos en training, validaci√≥n y testing.
       ‚óã Obtener un mayor n√∫mero de datos.
       ‚óã Ajustar los par√°metros de nuestros modelos.
       ‚óã Utilizar modelos m√°s simples en caso de ser posible 
         (PARSIMONIA).
    ¬øY el Underfitting?
    ‚úì Sucede cuando nuestro modelo no es capaz de 
      identificar patrones. Por lo que tendr√° siempre 
      p√©simos resultados. Ì∏∞Ì†Ω
    ‚úì Existen diferentes formas de prevenir el 
      Underfitting:
       ‚óã Tratar los datos correctamente, 
        eliminando outliers y variables 
        innecesarias.
       ‚óã Utilizar modelos m√°s complejos.
       ‚óã Ajustar los par√°metros de nuestros 
        modelos.
                   Diferencias
                        REEMPLAZAR 
                         POR VIDEO
   Overfitting y 
   Underfitting
    En el Machine Learning
       M√©tricas y 
       evaluaci√≥n
    M√©tricas y 
    Evaluaci√≥n
     Resulta importante comenzar a hablar acerca 
     de las diferentes m√©tricas que existen 
     dentro del Machine Learning para 
     evaluar la performance de nuestro 
     modelo. 
     Simplemente realizaremos una primera 
     aproximaci√≥n a la tem√°tica, en pr√≥ximas 
     clases el tema de: Validaci√≥n de resultados 
     del Modelo y Tuneo se ver√° y tratar√° de 
     manera detallada. Ì±âÌ†Ω
      M√©tricas para 
       Algoritmos 
     de Clasificaci√≥n 
   Matriz de Confusi√≥n
    ‚úì Herramienta que permite visualizar el 
      desempe√±o de un algoritmo  de 
      aprendizaje supervisado. 
    ‚úì Cada columna de la matriz representa el 
      n√∫mero de predicciones de cada clase, 
      mientras que cada fila representa a las 
      instancias en la clase real. 
      En t√©rminos pr√°cticos entonces, nos 
      permite ver qu√© tipos de aciertos y 
      errores est√° teniendo nuestro modelo.
    Matriz de Confusi√≥n
                            Interpretaci√≥n:
                             ‚úì Verdadero Positivo (TP): Predije que era 
                                positivo y lo era.
                             ‚úì Verdadero Negativo (TN): Predije que era 
                                falso y lo era.
                             ‚úì Falso Positivo (FP): Predije que era positivo 
                                pero result√≥ ser negativo.
                             ‚úì Falso Negativo (FN): Predije que era negativo 
                                pero result√≥ siendo positivo.
          Los Verdaderos Positivos como Negativos son aciertos. Los Falsos Negativos como Positivos son 
          errores.
         Ejemplo Titanic
                                                   Clase Predicha
               a                        No Sobrevivieron    Sobrevivieron
               r
             e e
             s d     No Sobrevivieron         513                110
             a a
             l d
               r
             C e
               V     Sobrevivieron            103                283
    Matriz de confusi√≥n 
      y sus m√©tricas
  M√©tricas para evaluaci√≥n 
  de clasificadores
                                           M√âTRICAS
       Exactitud            Precisi√≥n          Sensibilidad       Especificidad          F1 Score
    La Exactitud o Accuracy
                      Ì±âÌ†Ω se refiere a lo cerca que est√° el resultado 
                      de una medici√≥n del valor verdadero. En 
                      t√©rminos estad√≠sticos, la exactitud est√° 
                      relacionada con el sesgo de una estimaci√≥n. Se 
                      representa por la proporci√≥n entre los positivos 
                      reales predichos por el algoritmo y todos los 
                      casos positivos.
                      En forma pr√°ctica la Exactitud es  el % total de 
                      elementos clasificados correctamente.
                      (VP+VN)/(VP+FP+FN+VN) * 100
     Precisi√≥n (Positive 
     Predictive rate)
                     Ì±âÌ†Ω Se refiere a la dispersi√≥n del conjunto de 
                     valores obtenidos a partir de mediciones 
                     repetidas de una magnitud. Cuanto menor es la 
                     dispersi√≥n mayor la precisi√≥n. Es una proporci√≥n 
                     entre el n√∫mero de predicciones correctas (tanto 
                     positivas como negativas) y el total de 
                     predicciones. En forma pr√°ctica, es  el porcentaje 
                     de casos positivos detectados y nos sirve para 
                     medir la¬†calidad¬†del modelo de ML en tareas de 
                     clasificaci√≥n.
                     Se calcula como:  VP/(VP+FP)
     Sensibilidad o Tasa 
     de Verdaderos 
     Positivos Ì±âÌ†Ω Es la proporci√≥n de casos positivos que fueron 
                      correctamente identificadas por el algoritmo.
                      En t√©rminos pr√°cticos ser√≠a la capacidad de una 
                      prueba para identificar correctamente a las 
                      personas con la caracter√≠stica (e.g. enfermedad) 
                      Se calcula:  VP/(VP+FN) o lo que ser√≠a igual en 
                      t√©rminos de salud:  Verdaderos positivos 
    Especificidad - Tasa de 
    Verdaderos Negativos
                  Ì±âÌ†Ω Se trata de los casos negativos que el algoritmo ha clasificado 
                  correctamente.  Expresa cu√°n bien puede el modelo detectar esa 
                  clase.
                  En t√©rminos pr√°cticos es la capacidad de la prueba para identificar 
                  correctamente a las personas sin la caracter√≠stica (e.g enfermedad) 
                  Se calcula:  VN/(VN+FP) o en t√©rminos de salud:  Verdaderos 
                  Negativos 
  En resumen
       F1 ‚Äì Score
       Ì±âÌ†Ω Esta es otra m√©trica muy empleada porque        Los valores t√≠picos est√°n entre 0 y 1.
       nos resume la Precisi√≥n (Precisi√≥n) y 
       Sensibilidad (Recall) en una sola m√©trica.         Se calcula:  
       Es una medida general del desempe√±o de un          2 * (Recall * Precision) / (Recall + Precision)
       modelo combinando Precisi√≥n y Sensibilidad.
       Un valor alto indica pocos Falsos Positivos y 
       pocos Falsos Negativos, identificando las 
       amenazas reales. 
     Algunas 
     consideraciones de 
     F1 - Score                                      ‚úì Baja precisi√≥n y bajo recall Ì±âÌ†Ω El modelo 
        ‚úì Alta precisi√≥n y alto recall Ì±âÌ†Ω el modelo 
           maneja perfectamente esa clase.              no logra clasificar la clase correctamente.
        ‚úì Alta precisi√≥n y bajo recall Ì±âÌ†Ω el modelo no 
           detecta la clase muy bien, pero cuando lo 
           hace es altamente confiable.
        ‚úì Baja precisi√≥n y alto recall Ì±âÌ†Ω El modelo 
           detecta bien la clase,  pero tambi√©n 
           incluye muestras de la otra clase.
      PARA RECORDAR
   Inteligencia Artificial
   Por √∫ltimo hablamos sobre algunas m√©tricas para 
   evaluaci√≥n de Modelos de Regresi√≥n. Recordemos que 
   aqu√≠, predecimos o estimamos el valor num√©rico de una 
   cantidad desconocida, de acuerdo con unas 
   caracter√≠sticas dadas. 
   La diferencia entre la predicci√≥n y el valor real es 
   el Error, este es una variable aleatoria, que puede 
   depender de las caracter√≠sticas dadas. Ì∏âÌ†Ω
       Para pensar
   Si tuvi√©ramos que cuantificar el 
   desempe√±o de diferentes pruebas para 
   detectar  COVID ¬øQu√© m√©trica ser√≠a la 
   apropiada y por qu√©? 
   Contesta mediante el chat de Zoom 
  M√©tricas para Algoritmos 
      de Regresi√≥n 
        M√©tricas para algoritmos 
        de Regresi√≥n
         En la actualidad hay muchas formas para        Existen varias m√©tricas m√°s como ser 
        estimar el rendimiento y evaluar el ajuste      por ejemplo, el R cuadrado ajustado (R¬≤), 
             del modelo de regresi√≥n, las m√°s           MSPE ‚Äì Error de porcentaje cuadr√°tico 
                    importantes son:                    medio, entre otras.
         ‚úì Error Cuadr√°tico Medio (RMSE, por 
            sus  siglas  en  ingl√©s,  Root  Mean 
            Squared Error).
         ‚úì Error  Absoluto  Medio  (MAE,  Mean 
            Absolute Error). 
         ‚úì R-Cuadrado.
    Error cuadr√°tico medio 
    (RMSE)
     Ì±âÌ†Ω Es la m√©trica m√°s com√∫nmente utilizada 
     para las tareas de regresi√≥n y representa a 
     la ra√≠z cuadrada de la distancia 
     cuadrada promedio entre el valor real 
     y el valor pronosticado.
     Indica el ajuste absoluto del modelo a los 
     datos, cu√°n cerca est√°n los puntos de 
     datos observados de los valores 
     predichos del modelo.
   Error absoluto 
   medio (MAE)
    Ì±âÌ†Ω Es la diferencia absoluta entre el valor 
    objetivo y el valor predicho por el modelo. Es 
    m√°s robusto para los valores at√≠picos y no penaliza 
    los errores tan extremadamente como el MSE.  
    Este tipo de m√©trica, no es adecuada para 
    aplicaciones en las que desea prestar m√°s atenci√≥n a 
    los valores at√≠picos.
     R2
    Ì±âÌ†Ω indica la bondad o la aptitud del modelo, a 
    menudo se utiliza con fines descriptivos y muestra 
    que tambi√©n las variables independientes 
    seleccionadas explican la variabilidad en sus 
    variables dependientes. 
    R-cuadrado tiene la propiedad √∫til de que su 
    escala es intuitiva, va de 0 a 1, con 0 indicando 
    que el modelo propuesto no mejora la predicci√≥n 
    sobre el modelo medido y 1 indica una 
    predicci√≥n perfecta.¬†
       Para pensar
   Imaginemos que estamos esperando un mail 
   importante y se categoriza como spam ¬øCu√°l es el 
   problema? ¬øC√≥mo podemos utilizar las m√©tricas para 
   reducir el margen de error? 
   Contesta mediante el chat de Zoom 
       Ejemplo en vivo
   Exploremos c√≥mo se obtienen las diversas m√©tricas 
   para evaluar el desempe√±o de un modelo de 
   clasificaci√≥n y regresi√≥n.
   Utilizaremos el notebook  Clase_19.ipynb 
   dentro de la carpeta de clase.
                Recordemos‚Ä¶
                          Generamos recomendaciones 
                          basados en insights obtenidos
         Clase 17         Definimos Objetivo, Contexto y 
      Estructurando un    Problema comercial
     Proyecto DS- Parte II
                          Contexto anal√≠tico, Limpieza 
                          de datos y EDA 
                          Obtenemos conclusiones y 
                          puntos importantes a resaltar
                            5
         Pr√°ctica integradora 
        Deber√°s entregar el quinto avance de tu proyecto 
       final. Continuaremos hablando sobre lo trabajado en 
       el desaf√≠o ‚ÄúEstructurando un proyecto de DS Parte II‚Äù. 
             DESAF√çO 
             ENTREGABLE
        Estructurando un proyecto de 
        DS-parte III
    Consigna                                               Aspectos a incluir
      ‚úì Crear√°s un notebook que complemente el              ‚úì El c√≥digo debe estar hecho en un 
          trabajo realizado en los siguientes                   notebook y debe estar probado.
          apartados:                                       Formato
            -   i) elegir un m√©todo de feature              ‚úì Entregar un archivo con formato .ipynb. 
                selection para reducir la                       Debe tener el nombre 
                dimensionalidad del dataset,                    ‚ÄúProyecto_ParteIII_+Apellido.ipynb‚Äù  
            -   ii) elegir un algoritmo de regresi√≥n o 
                clasificaci√≥n para entrenar con los 
                datos elegidos,                            Sugerencias
            -    iii) c√°lculo de m√©tricas para validar      ‚úì Preparar el c√≥digo y probar los 
                el modelo                                       resultados con subconjuntos del 
            -   iv) generar conclusiones con base en            conjunto original.
                los resultados obtenidos.                   ‚úì Video explicativo
        Evaluando modelos 
                 ML
      Se propone complementar el an√°lisis desarrollado 
         hasta el momento del proyecto final. 
             DESAF√çO 
             COMPLEMENTARIO
        Evaluando modelos ML
       Consigna
         ‚úì Continuaremos trabajando con base              Aspectos a incluir
             en lo realizado en el Desaf√≠o                  ‚úì El c√≥digo debe estar hecho en un notebook 
             entregable: Estructurando un                       y debe estar probado.
             proyecto de DS-Parte II y III, en esta       Formato
             oportunidad deber√°s complementar 
             con lo siguiente:                              ‚úì Entregar un archivo con formato .ipynb. 
         ‚úì Generar una evaluaci√≥n de modelos                    Debe tener el nombre 
             apropiados para el problema de                     ‚ÄúProyecto_ComplementarioI_+Apellido.ipyn
             inter√©s                                            b‚Äù  
         ‚úì Identificar por medio de las m√©tricas          Sugerencias
             generadas si se puede tener una                ‚úì Preparar el c√≥digo y probar los resultados 
             situaci√≥n de overfitting (sobreajuste)             con subconjuntos del conjunto original.
             o underfitting (subajuste), 
             discutiendo posibles formas de 
             mejora
       Para pensar
   ¬øC√≥mo podemos utilizar la informaci√≥n de la compra 
   de libros, por ejemplo, respecto al comportamiento de 
   los clientes para mejorar las utilidades del negocio? 
   Contesta mediante el chat de Zoom 
       CLASE N¬∞19                                    Conjunto de validaci√≥n: fracci√≥n de datos 
                                                     (usualmente 20-30%) que se utiliza para validar 
                                                     algoritmos de Machine Learning supervisado con 
       Glosario                                      el fin de identificar si el modelo aprendi√≥ 
                                                     correctamente
   Instancia : unidad fundamental que representa 
   a los individuos u objetos que conforman un       Overfitting: cuando un modelo obtiene muy 
   dataset                                           buenas m√©tricas en el conjunto de 
                                                     entrenamiento pero muy malas en el conjunto de 
   Caracter√≠stica o feature : variables que          test
   representan los atributos de las instancias de 
   un dataset                                        Underfitting: Cuando el modelo no es capaz de 
                                                     reproducir correctamente los patrones y 
   Entrenamiento: fase donde se detectan las         relaciones fundamentales del fen√≥meno de 
   asociaciones y tendencias de un dataset           inter√©s.
   Conjunto de entrenamiento: fracci√≥n de            Matriz de confusi√≥n:matriz que se construye 
   datos (usualmente 70-80%) que se utiliza para     para validar el performance de un modelo de 
   entrenar algoritmos de Machine Learning           clasificaci√≥n, contiene informaci√≥n sobre el 
   supervisado con el fin de entender patrones y     accuracy, precisi√≥n, exactitud, sensibilidad y 
   tendencias                                        especificidad del algoritmo
                                                     Dataset: conjunto de filas y columnas que 
                                                     guardan informaci√≥n hist√≥rica 
     ¬øQuieres saber m√°s?
     Te dejamos material 
     ampliado de la clase
       MATERIAL AMPLIADO
    Recursos multimedia
    ‚úì Hoja de referencia de consejos y trucos sobre Aprendizaje 
      Autom√°tico
       | Stanford Edu
    ‚úì Selecci√≥n de M√©tricas para aprendizaje autom√°tico | 
      Fayrix
    ‚úì Aprendizaje autom√°tico y m√©tricas de regresi√≥n | 
      Sitiobigdata.com
    ‚úì Error Cuadr√°tico Medio para Regresi√≥n | Iartificial.net
      ¬øPreguntas?
                   Resumen 
               de la clase hoy
              ‚úì Conceptos b√°sicos de ML
              ‚úì M√©tricas de Clasificaci√≥n
              ‚úì Regresi√≥n en Machine Learning
      Opina y valora 
       esta clase
        Muchas 
        gracias.
